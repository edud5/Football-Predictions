{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('jugadores_ready.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_equip = list(df['equipo'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Team(E):\n",
    "    partidos = df.groupby('equipo').get_group(E)\n",
    "    x = 1 #jornada a empezar\n",
    "    lista = []\n",
    "    for i in range(36): #numero de filas\n",
    "        datos_a = pd.DataFrame(np.concatenate(np.asarray(partidos[partidos.jornada == i+x].iloc[0:12,0:7]))).T\n",
    "        datos_a = datos_a.reset_index()\n",
    "        corners_a = partidos[partidos.jornada == i+x].iloc[0:12,-1].sum()#suma de los corners\n",
    "        datos_a.insert(6,'corners', corners_a)\n",
    "\n",
    "\n",
    "        datos_b = pd.DataFrame(np.concatenate(np.asarray(partidos[partidos.jornada == i+x+1].iloc[0:12,0:7]))).T\n",
    "        datos_b = datos_b.reset_index()\n",
    "        corners_b = partidos[partidos.jornada == i+x+1].iloc[0:12,-1].sum()#suma de los corners\n",
    "        datos_b.insert(6,'corners', corners_b)\n",
    "\n",
    "        jugadores_c = pd.DataFrame(np.concatenate(np.asarray(partidos[partidos.jornada == i+x+2].iloc[0:12,0:1]))).T\n",
    "        corners_c = partidos[partidos.jornada == i+x+2].iloc[0:12,-1].sum()\n",
    "        jugadores_c.insert(11,'corners', corners_c)\n",
    "\n",
    "        total_v1 = pd.concat([datos_a,datos_b,jugadores_c],axis=1,ignore_index=True)\n",
    "        total_v1 = total_v1.drop([79,86,87,88,89,91],axis=1)\n",
    "        lista.append(total_v1)\n",
    "\n",
    "    df_final = pd.concat(lista)\n",
    "    df_final = df_final.reset_index()\n",
    "\n",
    "    df_final = df_final.drop(0,axis=1)\n",
    "    df_final = df_final.drop('index',axis=1)\n",
    "    \n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMTeam(X):\n",
    "    #df_final=X    \n",
    "    df_final = Team(X)\n",
    "    df_final = df_final.replace(np.nan, 0.0)\n",
    "    df_final[169] = df_final[169].replace((0,1,2,3),0)\n",
    "    df_final[169] = df_final[169].replace((4,5,6),1)\n",
    "    df_final[169] = df_final[169].replace((7,8,9,10,11,12,13),2)\n",
    "    X = df_final.iloc[:,:162]\n",
    "    y = df_final.iloc[:,162:163]\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    #y = y.replace(np.nan,0.0)\n",
    "    y = y[:, 0]\n",
    "    # Build a forest and compute the feature importances\n",
    "    forest =  clf = svm.SVC(kernel='sigmoid')\n",
    "\n",
    " #Change for SVM\n",
    "   # forest.fit(X, y)\n",
    "    #importances = forest.feature_importances_\n",
    "    #std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "    #indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    #print(\"Feature ranking:\")\n",
    "\n",
    "    #for f in range(X.shape[1]):\n",
    "      #  print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "    #X = df_final.iloc[:,indices[:50]]\n",
    "    #X=X.replace(np.nan,0)\n",
    "    #X = np.array(X)\n",
    "\n",
    "    loo = LeaveOneOut()\n",
    "    loo.get_n_splits(X)\n",
    "    yhat=[]\n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        #CLASIFICADOR SVM\n",
    "        clf = svm.SVC(kernel='sigmoid')\n",
    "        clf.fit(X_train, y_train)  ##X_train, y_train\n",
    "        yhat1 = clf.predict(X_test)\n",
    "        yhat.append(yhat1)       \n",
    "        \n",
    "    #print(\"Accuracy: \", accuracy_score(y,yhat))\n",
    "    return accuracy_score(y,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'girona': 0.6666666666666666,\n",
       " 'valladolid': 0.4166666666666667,\n",
       " 'betis': 0.5,\n",
       " 'levante': 0.4166666666666667,\n",
       " 'celta': 0.0,\n",
       " 'espanyol': 0.5,\n",
       " 'villarreal': 0.3055555555555556,\n",
       " 'real_sociedad': 0.5277777777777778,\n",
       " 'barcelona': 0.0,\n",
       " 'alaves': 0.5833333333333334,\n",
       " 'eibar': 0.4444444444444444,\n",
       " 'huesca': 0.5,\n",
       " 'rayo': 0.5,\n",
       " 'sevilla': 0.5277777777777778,\n",
       " 'real_madrid': 0.4166666666666667,\n",
       " 'getafe': 0.5,\n",
       " 'valencia': 0.4722222222222222,\n",
       " 'atletico': 0.4166666666666667,\n",
       " 'athletic': 0.6944444444444444,\n",
       " 'leganes': 0.5277777777777778}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_Acc = []\n",
    "for i in list_equip:\n",
    "    L_Acc.append(SVMTeam(i))\n",
    "Dicc = dict(zip(list_equip,L_Acc))\n",
    "Dicc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4458333333333334"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Media Adaboost: 0.4375\n",
    "Media_Random_Forest = sum(L_Acc)/20\n",
    "Media_Random_Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KERNELS: linear=0.41, poly=0.43, rbf=0.425, sigmoid=0.44 (En sigmoid hay 3 que dan 0, si obviamos esos, la media es de 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
