{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('jugadores_ready.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_equip = list(df['equipo'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Team(E):\n",
    "    partidos = df.groupby('equipo').get_group(E)\n",
    "    x = 1 #jornada a empezar\n",
    "    lista = []\n",
    "    for i in range(36): #numero de filas\n",
    "        datos_a = pd.DataFrame(np.concatenate(np.asarray(partidos[partidos.jornada == i+x].iloc[0:12,0:7]))).T\n",
    "        datos_a = datos_a.reset_index()\n",
    "        corners_a = partidos[partidos.jornada == i+x].iloc[0:12,-1].sum()#suma de los corners\n",
    "        datos_a.insert(6,'corners', corners_a)\n",
    "\n",
    "\n",
    "        datos_b = pd.DataFrame(np.concatenate(np.asarray(partidos[partidos.jornada == i+x+1].iloc[0:12,0:7]))).T\n",
    "        datos_b = datos_b.reset_index()\n",
    "        corners_b = partidos[partidos.jornada == i+x+1].iloc[0:12,-1].sum()#suma de los corners\n",
    "        datos_b.insert(6,'corners', corners_b)\n",
    "\n",
    "        jugadores_c = pd.DataFrame(np.concatenate(np.asarray(partidos[partidos.jornada == i+x+2].iloc[0:12,0:1]))).T\n",
    "        corners_c = partidos[partidos.jornada == i+x+2].iloc[0:12,-1].sum()\n",
    "        jugadores_c.insert(11,'corners', corners_c)\n",
    "\n",
    "        total_v1 = pd.concat([datos_a,datos_b,jugadores_c],axis=1,ignore_index=True)\n",
    "        total_v1 = total_v1.drop([79,86,87,88,89,91],axis=1)\n",
    "        lista.append(total_v1)\n",
    "\n",
    "    df_final = pd.concat(lista)\n",
    "    df_final = df_final.reset_index()\n",
    "\n",
    "    df_final = df_final.drop(0,axis=1)\n",
    "    df_final = df_final.drop('index',axis=1)\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaTeam(X):\n",
    "    #df_final=X    \n",
    "    df_final = Team(X)\n",
    "    df_final = df_final.replace(np.nan, 0.0)\n",
    "    df_final[169] = df_final[169].replace((0,1,2,3),0)\n",
    "    df_final[169] = df_final[169].replace((4,5,6),1)\n",
    "    df_final[169] = df_final[169].replace((7,8,9,10,11,12,13),2)\n",
    "    X = df_final.iloc[:,:162]\n",
    "    y = df_final.iloc[:,162:163]\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    #y = y.replace(np.nan,0.0)\n",
    "    y = y[:, 0]\n",
    "    # Build a forest and compute the feature importances\n",
    "    forest = AdaBoostClassifier (n_estimators=250,random_state=0) #Change for Adaboost\n",
    "    forest.fit(X, y)\n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    #print(\"Feature ranking:\")\n",
    "\n",
    "    #for f in range(X.shape[1]):\n",
    "      #  print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "    X = df_final.iloc[:,indices[:50]]\n",
    "    X=X.replace(np.nan,0)\n",
    "    X = np.array(X)\n",
    "\n",
    "    loo = LeaveOneOut()\n",
    "    loo.get_n_splits(X)\n",
    "    yhat=[]\n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        #CLASIFICADOR AdaBoost\n",
    "        clf = AdaBoostClassifier(n_estimators=500)\n",
    "        clf.fit(X_train, y_train)  ##X_train, y_train\n",
    "        yhat1 = clf.predict(X_test)\n",
    "        yhat.append(yhat1)       \n",
    "        \n",
    "    #print(\"Accuracy: \", accuracy_score(y,yhat))\n",
    "    return accuracy_score(y,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3055555555555556"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaTeam('barcelona')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_Acc = []\n",
    "for i in list_equip:\n",
    "    L_Acc.append(AdaTeam(i))\n",
    "L_Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dicc = dict(zip(list_equip,L_Acc))\n",
    "Dicc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(L_Acc)/20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
